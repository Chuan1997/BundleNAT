@article{YANG2024103814,
title = {Non-autoregressive personalized bundle generation},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103814},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103814},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001730},
author = {Wenchuan Yang and Cheng Yang and Jichao Li and Yuejin Tan and Xin Lu and Chuan Shi},
keywords = {Personalized bundle generation, Non-autoregressive decoding, Transformer},
abstract = {The personalized bundle generation problem, which aims to create a preferred bundle for user from numerous candidate items, receives increasing attention in recommendation. However, existing works ignore the order-invariant nature of the bundle and adopt sequential modeling methods as the solution, which might introduce inductive bias and cause a large latency in prediction. To address this problem, we propose to perform the bundle generation via non-autoregressive mechanism and design a novel encoderâ€“decoder framework named BundleNAT, which can effectively output the targeted bundle in one-shot without relying on any inherent order. In detail, instead of learning sequential dependency, we propose to adopt pre-training techniques and graph neural network to fully embed user-based preference and item-based compatibility information, and use a self-attention based encoder to further extract global dependency pattern. We then design a permutation-equivariant decoding architecture that is able to directly output the desired bundle in a one-shot manner. Experiments on three real-world datasets from Youshu and Netease show the proposed BundleNAT significantly outperforms the current state-of-the-art methods in average by up to 35.92%, 10.97% and 23.67% absolute improvements in Precision, Precision+, and Recall, respectively.}
}